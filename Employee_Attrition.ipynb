{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eIxZRtMviPK"
      },
      "source": [
        "## Imports / Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPaUkmiMIerz",
        "outputId": "e66d0dda-f9c4-48dd-b5d0-12ec3a92f558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OACdgNQ4DiBw",
        "outputId": "c7767667-eedb-4579-f005-d6a0a0e7960e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Looking for: ['python=3.9', 'jupyterlab', 'swig', 'cmake']\n",
            "\n",
            "conda-forge/linux-64                                        Using cache\n",
            "conda-forge/noarch                                          Using cache\n",
            "Transaction\n",
            "\n",
            "  Prefix: /usr/local/envs/autosklearn-env\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - python=3.9\n",
            "   - jupyterlab\n",
            "   - swig\n",
            "   - cmake\n",
            "\n",
            "\n",
            "  Package                                 Version  Build               Channel           Size\n",
            "───────────────────────────────────────────────────────────────────────────────────────────────\n",
            "  Install:\n",
            "───────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  \u001b[32m+ python_abi                   \u001b[0m             3.9  8_cp39              conda-forge        7kB\n",
            "  \u001b[32m+ tzdata                       \u001b[0m           2025b  h78e105d_0          conda-forge      123kB\n",
            "  \u001b[32m+ ca-certificates              \u001b[0m       2025.7.14  hbd8a1cb_0          conda-forge      156kB\n",
            "  \u001b[32m+ ld_impl_linux-64             \u001b[0m            2.44  h1423503_1          conda-forge      676kB\n",
            "  \u001b[32m+ _libgcc_mutex                \u001b[0m             0.1  conda_forge         conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libgomp                      \u001b[0m          15.1.0  h767d61c_4          conda-forge      447kB\n",
            "  \u001b[32m+ _openmp_mutex                \u001b[0m             4.5  2_gnu               conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libgcc                       \u001b[0m          15.1.0  h767d61c_4          conda-forge      824kB\n",
            "  \u001b[32m+ rhash                        \u001b[0m           1.4.6  hb9d3cd8_1          conda-forge      194kB\n",
            "  \u001b[32m+ libuv                        \u001b[0m          1.51.0  hb03c661_1          conda-forge      895kB\n",
            "  \u001b[32m+ c-ares                       \u001b[0m          1.34.5  hb9d3cd8_0          conda-forge      207kB\n",
            "  \u001b[32m+ openssl                      \u001b[0m           3.5.1  h7b32b05_0          conda-forge        3MB\n",
            "  \u001b[32m+ ncurses                      \u001b[0m             6.5  h2d0b736_3          conda-forge      892kB\n",
            "  \u001b[32m+ libzlib                      \u001b[0m           1.3.1  hb9d3cd8_2          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libnsl                       \u001b[0m           2.0.1  hb9d3cd8_1          conda-forge       34kB\n",
            "  \u001b[32m+ liblzma                      \u001b[0m           5.8.1  hb9d3cd8_2          conda-forge      113kB\n",
            "  \u001b[32m+ libexpat                     \u001b[0m           2.7.1  hecca717_0          conda-forge       75kB\n",
            "  \u001b[32m+ libffi                       \u001b[0m           3.4.6  h2dba641_1          conda-forge       57kB\n",
            "  \u001b[32m+ yaml                         \u001b[0m           0.2.5  h280c20c_3          conda-forge       85kB\n",
            "  \u001b[32m+ libstdcxx                    \u001b[0m          15.1.0  h8f9b012_4          conda-forge        4MB\n",
            "  \u001b[32m+ libgcc-ng                    \u001b[0m          15.1.0  h69a702a_4          conda-forge       29kB\n",
            "  \u001b[32m+ libedit                      \u001b[0m    3.1.20250104  pl5321h7949ede_0    conda-forge      135kB\n",
            "  \u001b[32m+ readline                     \u001b[0m             8.2  h8c095d6_2          conda-forge      282kB\n",
            "  \u001b[32m+ libssh2                      \u001b[0m          1.11.1  hcf80075_0          conda-forge      305kB\n",
            "  \u001b[32m+ libsqlite                    \u001b[0m          3.50.4  h0c1763c_0          conda-forge      933kB\n",
            "  \u001b[32m+ tk                           \u001b[0m          8.6.13  noxft_hd72426e_102  conda-forge        3MB\n",
            "  \u001b[32m+ libstdcxx-ng                 \u001b[0m          15.1.0  h4852527_4          conda-forge       29kB\n",
            "  \u001b[32m+ zstd                         \u001b[0m           1.5.7  hb8e6e7a_2          conda-forge      568kB\n",
            "  \u001b[32m+ libev                        \u001b[0m            4.33  hd590300_2          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libxcrypt                    \u001b[0m          4.4.36  hd590300_1          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ bzip2                        \u001b[0m           1.0.8  h4bc722e_7          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libsodium                    \u001b[0m          1.0.20  h4ab18f5_0          conda-forge      206kB\n",
            "  \u001b[32m+ keyutils                     \u001b[0m           1.6.1  h166bdaf_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libuuid                      \u001b[0m          2.38.1  h0b41bf4_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libnghttp2                   \u001b[0m          1.64.0  h161d5f1_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ pcre2                        \u001b[0m           10.45  hc749103_0          conda-forge        1MB\n",
            "  \u001b[32m+ krb5                         \u001b[0m          1.21.3  h659f571_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ python                       \u001b[0m          3.9.23  hc30ae73_0_cpython  conda-forge       24MB\n",
            "  \u001b[32m+ swig                         \u001b[0m           4.3.1  h32e72b7_1          conda-forge        1MB\n",
            "  \u001b[32m+ zeromq                       \u001b[0m           4.3.5  h3b0a872_7          conda-forge      335kB\n",
            "  \u001b[32m+ libcurl                      \u001b[0m          8.14.1  h332b0f4_0          conda-forge      450kB\n",
            "  \u001b[32m+ cmake                        \u001b[0m           4.0.3  h74e3db0_0          conda-forge       20MB\n",
            "  \u001b[32m+ wheel                        \u001b[0m          0.45.1  pyhd8ed1ab_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ setuptools                   \u001b[0m          80.9.0  pyhff2d567_0        conda-forge      749kB\n",
            "  \u001b[32m+ pip                          \u001b[0m            25.2  pyh8b19718_0        conda-forge        1MB\n",
            "  \u001b[32m+ pysocks                      \u001b[0m           1.7.1  pyha55dd90_7        conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ parso                        \u001b[0m           0.8.4  pyhd8ed1ab_1        conda-forge       75kB\n",
            "  \u001b[32m+ wcwidth                      \u001b[0m          0.2.13  pyhd8ed1ab_1        conda-forge       33kB\n",
            "  \u001b[32m+ charset-normalizer           \u001b[0m           3.4.2  pyhd8ed1ab_0        conda-forge       50kB\n",
            "  \u001b[32m+ pure_eval                    \u001b[0m           0.2.3  pyhd8ed1ab_1        conda-forge       17kB\n",
            "  \u001b[32m+ executing                    \u001b[0m           2.2.0  pyhd8ed1ab_0        conda-forge       30kB\n",
            "  \u001b[32m+ asttokens                    \u001b[0m           3.0.0  pyhd8ed1ab_1        conda-forge       28kB\n",
            "  \u001b[32m+ pycparser                    \u001b[0m            2.22  pyh29332c3_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ pytz                         \u001b[0m          2025.2  pyhd8ed1ab_0        conda-forge      189kB\n",
            "  \u001b[32m+ soupsieve                    \u001b[0m             2.7  pyhd8ed1ab_0        conda-forge       38kB\n",
            "  \u001b[32m+ webencodings                 \u001b[0m           0.5.1  pyhd8ed1ab_3        conda-forge       15kB\n",
            "  \u001b[32m+ pickleshare                  \u001b[0m           0.7.5  pyhd8ed1ab_1004     conda-forge       12kB\n",
            "  \u001b[32m+ decorator                    \u001b[0m           5.2.1  pyhd8ed1ab_0        conda-forge       14kB\n",
            "  \u001b[32m+ json5                        \u001b[0m          0.12.0  pyhd8ed1ab_0        conda-forge       34kB\n",
            "  \u001b[32m+ pygments                     \u001b[0m          2.19.2  pyhd8ed1ab_0        conda-forge      889kB\n",
            "  \u001b[32m+ pandocfilters                \u001b[0m           1.5.0  pyhd8ed1ab_0        conda-forge       12kB\n",
            "  \u001b[32m+ defusedxml                   \u001b[0m           0.7.1  pyhd8ed1ab_0        conda-forge       24kB\n",
            "  \u001b[32m+ python-fastjsonschema        \u001b[0m          2.21.1  pyhd8ed1ab_0        conda-forge      226kB\n",
            "  \u001b[32m+ typing_utils                 \u001b[0m           0.1.0  pyhd8ed1ab_1        conda-forge       15kB\n",
            "  \u001b[32m+ six                          \u001b[0m          1.17.0  pyhe01879c_1        conda-forge       18kB\n",
            "  \u001b[32m+ lark                         \u001b[0m           1.2.2  pyhd8ed1ab_1        conda-forge       92kB\n",
            "  \u001b[32m+ ptyprocess                   \u001b[0m           0.7.0  pyhd8ed1ab_1        conda-forge       19kB\n",
            "  \u001b[32m+ cached_property              \u001b[0m           1.5.2  pyha770c72_1        conda-forge       11kB\n",
            "  \u001b[32m+ types-python-dateutil        \u001b[0m  2.9.0.20250708  pyhd8ed1ab_0        conda-forge       25kB\n",
            "  \u001b[32m+ typing_extensions            \u001b[0m          4.14.1  pyhe01879c_0        conda-forge       51kB\n",
            "  \u001b[32m+ sniffio                      \u001b[0m           1.3.1  pyhd8ed1ab_1        conda-forge       15kB\n",
            "  \u001b[32m+ hyperframe                   \u001b[0m           6.1.0  pyhd8ed1ab_0        conda-forge       17kB\n",
            "  \u001b[32m+ hpack                        \u001b[0m           4.1.0  pyhd8ed1ab_0        conda-forge       31kB\n",
            "  \u001b[32m+ certifi                      \u001b[0m       2025.7.14  pyhd8ed1ab_0        conda-forge      160kB\n",
            "  \u001b[32m+ zipp                         \u001b[0m          3.23.0  pyhd8ed1ab_0        conda-forge       23kB\n",
            "  \u001b[32m+ comm                         \u001b[0m           0.2.3  pyhe01879c_0        conda-forge       15kB\n",
            "  \u001b[32m+ nest-asyncio                 \u001b[0m           1.6.0  pyhd8ed1ab_1        conda-forge       12kB\n",
            "  \u001b[32m+ attrs                        \u001b[0m          25.3.0  pyh71513ae_0        conda-forge       57kB\n",
            "  \u001b[32m+ webcolors                    \u001b[0m         24.11.1  pyhd8ed1ab_0        conda-forge       18kB\n",
            "  \u001b[32m+ uri-template                 \u001b[0m           1.3.0  pyhd8ed1ab_1        conda-forge       24kB\n",
            "  \u001b[32m+ idna                         \u001b[0m            3.10  pyhd8ed1ab_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ platformdirs                 \u001b[0m           4.3.8  pyhe01879c_0        conda-forge       24kB\n",
            "  \u001b[32m+ python-json-logger           \u001b[0m           2.0.7  pyhd8ed1ab_0        conda-forge       13kB\n",
            "  \u001b[32m+ websocket-client             \u001b[0m           1.8.0  pyhd8ed1ab_1        conda-forge       47kB\n",
            "  \u001b[32m+ send2trash                   \u001b[0m           1.8.3  pyh0d859eb_1        conda-forge       23kB\n",
            "  \u001b[32m+ rfc3986-validator            \u001b[0m           0.1.1  pyh9f0ad1d_0        conda-forge        8kB\n",
            "  \u001b[32m+ prometheus_client            \u001b[0m          0.22.1  pyhd8ed1ab_0        conda-forge       53kB\n",
            "  \u001b[32m+ tomli                        \u001b[0m           2.2.1  pyhe01879c_2        conda-forge       21kB\n",
            "  \u001b[32m+ traitlets                    \u001b[0m          5.14.3  pyhd8ed1ab_1        conda-forge      110kB\n",
            "  \u001b[32m+ packaging                    \u001b[0m            25.0  pyh29332c3_1        conda-forge       62kB\n",
            "  \u001b[32m+ jedi                         \u001b[0m          0.19.2  pyhd8ed1ab_1        conda-forge      844kB\n",
            "  \u001b[32m+ prompt-toolkit               \u001b[0m          3.0.51  pyha770c72_0        conda-forge      272kB\n",
            "  \u001b[32m+ stack_data                   \u001b[0m           0.6.3  pyhd8ed1ab_1        conda-forge       27kB\n",
            "  \u001b[32m+ babel                        \u001b[0m          2.17.0  pyhd8ed1ab_0        conda-forge        7MB\n",
            "  \u001b[32m+ tinycss2                     \u001b[0m           1.4.0  pyhd8ed1ab_0        conda-forge       28kB\n",
            "  \u001b[32m+ bleach                       \u001b[0m           6.2.0  pyh29332c3_4        conda-forge      141kB\n",
            "  \u001b[32m+ jupyterlab_pygments          \u001b[0m           0.3.0  pyhd8ed1ab_2        conda-forge       19kB\n",
            "  \u001b[32m+ overrides                    \u001b[0m           7.7.0  pyhd8ed1ab_1        conda-forge       30kB\n",
            "  \u001b[32m+ python-dateutil              \u001b[0m     2.9.0.post0  pyhe01879c_2        conda-forge      233kB\n",
            "  \u001b[32m+ rfc3339-validator            \u001b[0m           0.1.4  pyhd8ed1ab_1        conda-forge       10kB\n",
            "  \u001b[32m+ rfc3987-syntax               \u001b[0m           1.1.0  pyhe01879c_1        conda-forge       23kB\n",
            "  \u001b[32m+ pexpect                      \u001b[0m           4.9.0  pyhd8ed1ab_1        conda-forge       54kB\n",
            "  \u001b[32m+ cached-property              \u001b[0m           1.5.2  hd8ed1ab_1          conda-forge        4kB\n",
            "  \u001b[32m+ mistune                      \u001b[0m           3.1.3  pyh29332c3_0        conda-forge       73kB\n",
            "  \u001b[32m+ exceptiongroup               \u001b[0m           1.3.0  pyhd8ed1ab_0        conda-forge       21kB\n",
            "  \u001b[32m+ typing-extensions            \u001b[0m          4.14.1  h4440ef1_0          conda-forge       90kB\n",
            "  \u001b[32m+ h11                          \u001b[0m          0.16.0  pyhd8ed1ab_0        conda-forge       38kB\n",
            "  \u001b[32m+ async-lru                    \u001b[0m           2.0.5  pyh29332c3_0        conda-forge       17kB\n",
            "  \u001b[32m+ h2                           \u001b[0m           4.2.0  pyhd8ed1ab_0        conda-forge       54kB\n",
            "  \u001b[32m+ importlib-metadata           \u001b[0m           8.7.0  pyhe01879c_1        conda-forge       35kB\n",
            "  \u001b[32m+ matplotlib-inline            \u001b[0m           0.1.7  pyhd8ed1ab_1        conda-forge       14kB\n",
            "  \u001b[32m+ jupyter_core                 \u001b[0m           5.8.1  pyh31011fe_0        conda-forge       60kB\n",
            "  \u001b[32m+ bleach-with-css              \u001b[0m           6.2.0  h82add2a_4          conda-forge        4kB\n",
            "  \u001b[32m+ arrow                        \u001b[0m           1.3.0  pyhd8ed1ab_1        conda-forge      100kB\n",
            "  \u001b[32m+ fqdn                         \u001b[0m           1.5.1  pyhd8ed1ab_1        conda-forge       17kB\n",
            "  \u001b[32m+ anyio                        \u001b[0m           4.9.0  pyh29332c3_0        conda-forge      126kB\n",
            "  \u001b[32m+ beautifulsoup4               \u001b[0m          4.13.4  pyha770c72_0        conda-forge      147kB\n",
            "  \u001b[32m+ ipython                      \u001b[0m          8.18.1  pyh707e725_3        conda-forge      591kB\n",
            "  \u001b[32m+ isoduration                  \u001b[0m         20.11.0  pyhd8ed1ab_1        conda-forge       20kB\n",
            "  \u001b[32m+ httpcore                     \u001b[0m           1.0.9  pyh29332c3_0        conda-forge       49kB\n",
            "  \u001b[32m+ httpx                        \u001b[0m          0.28.1  pyhd8ed1ab_0        conda-forge       63kB\n",
            "  \u001b[32m+ brotli-python                \u001b[0m           1.1.0  py39hf88036b_3      conda-forge      350kB\n",
            "  \u001b[32m+ debugpy                      \u001b[0m          1.8.15  py39haef64b4_0      conda-forge        2MB\n",
            "  \u001b[32m+ psutil                       \u001b[0m           7.0.0  py39h8cd3c5a_0      conda-forge      349kB\n",
            "  \u001b[32m+ markupsafe                   \u001b[0m           3.0.2  py39h9399b63_1      conda-forge       23kB\n",
            "  \u001b[32m+ rpds-py                      \u001b[0m          0.26.0  py39h20260ba_0      conda-forge      387kB\n",
            "  \u001b[32m+ jsonpointer                  \u001b[0m           3.0.0  py39hf3d152e_1      conda-forge       16kB\n",
            "  \u001b[32m+ pyyaml                       \u001b[0m           6.0.2  py39h9399b63_2      conda-forge      182kB\n",
            "  \u001b[32m+ pyzmq                        \u001b[0m          27.0.0  py39h4e4fb57_0      conda-forge      335kB\n",
            "  \u001b[32m+ tornado                      \u001b[0m           6.5.1  py39h8cd3c5a_0      conda-forge      650kB\n",
            "  \u001b[32m+ cffi                         \u001b[0m          1.17.1  py39h15c3d72_0      conda-forge      242kB\n",
            "  \u001b[32m+ zstandard                    \u001b[0m          0.23.0  py39h8cd3c5a_2      conda-forge      721kB\n",
            "  \u001b[32m+ argon2-cffi-bindings         \u001b[0m          21.2.0  py39h8cd3c5a_5      conda-forge       34kB\n",
            "  \u001b[32m+ jinja2                       \u001b[0m           3.1.6  pyhd8ed1ab_0        conda-forge      113kB\n",
            "  \u001b[32m+ referencing                  \u001b[0m          0.36.2  pyh29332c3_0        conda-forge       52kB\n",
            "  \u001b[32m+ jupyter_client               \u001b[0m           8.6.3  pyhd8ed1ab_1        conda-forge      106kB\n",
            "  \u001b[32m+ terminado                    \u001b[0m          0.18.1  pyh0d859eb_0        conda-forge       22kB\n",
            "  \u001b[32m+ urllib3                      \u001b[0m           2.5.0  pyhd8ed1ab_0        conda-forge      102kB\n",
            "  \u001b[32m+ argon2-cffi                  \u001b[0m          25.1.0  pyhd8ed1ab_0        conda-forge       19kB\n",
            "  \u001b[32m+ jsonschema-specifications    \u001b[0m        2025.4.1  pyh29332c3_0        conda-forge       19kB\n",
            "  \u001b[32m+ ipykernel                    \u001b[0m          6.30.0  pyh82676e8_0        conda-forge      120kB\n",
            "  \u001b[32m+ jupyter_server_terminals     \u001b[0m           0.5.3  pyhd8ed1ab_1        conda-forge       20kB\n",
            "  \u001b[32m+ requests                     \u001b[0m          2.32.4  pyhd8ed1ab_0        conda-forge       59kB\n",
            "  \u001b[32m+ jsonschema                   \u001b[0m          4.25.0  pyhe01879c_0        conda-forge       81kB\n",
            "  \u001b[32m+ jsonschema-with-format-nongpl\u001b[0m          4.25.0  he01879c_0          conda-forge        5kB\n",
            "  \u001b[32m+ nbformat                     \u001b[0m          5.10.4  pyhd8ed1ab_1        conda-forge      101kB\n",
            "  \u001b[32m+ jupyter_events               \u001b[0m          0.12.0  pyh29332c3_0        conda-forge       24kB\n",
            "  \u001b[32m+ nbclient                     \u001b[0m          0.10.2  pyhd8ed1ab_0        conda-forge       28kB\n",
            "  \u001b[32m+ nbconvert-core               \u001b[0m          7.16.6  pyh29332c3_0        conda-forge      201kB\n",
            "  \u001b[32m+ jupyter_server               \u001b[0m          2.16.0  pyhe01879c_0        conda-forge      344kB\n",
            "  \u001b[32m+ jupyterlab_server            \u001b[0m          2.27.3  pyhd8ed1ab_1        conda-forge       49kB\n",
            "  \u001b[32m+ jupyter-lsp                  \u001b[0m           2.2.6  pyhe01879c_0        conda-forge       58kB\n",
            "  \u001b[32m+ notebook-shim                \u001b[0m           0.2.4  pyhd8ed1ab_1        conda-forge       17kB\n",
            "  \u001b[32m+ jupyterlab                   \u001b[0m           4.4.5  pyhd8ed1ab_0        conda-forge        8MB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 154 packages\n",
            "\n",
            "  Total download: 95MB\n",
            "\n",
            "───────────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "\n",
            "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
            "Downloading  (1)   0%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
            "Downloading  (5)   0%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtzdata                                             123.0kB @ 793.2kB/s  0.2s\n",
            "ca-certificates                                    155.7kB @ 933.7kB/s  0.2s\n",
            "python_abi                                           7.0kB @  39.2kB/s  0.2s\n",
            "[+] 0.2s\n",
            "Downloading  (5)   1%\n",
            "Extracting   (3)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gc-ares                                             206.9kB @ 940.5kB/s  0.1s\n",
            "libgomp                                            447.3kB @   1.8MB/s  0.3s\n",
            "libnsl                                              33.7kB @ 131.7kB/s  0.1s\n",
            "libgcc                                             824.2kB @   2.8MB/s  0.1s\n",
            "libffi                                              57.4kB @ 198.2kB/s  0.1s\n",
            "[+] 0.3s\n",
            "Downloading  (5)   3%\n",
            "Extracting   (4)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gld_impl_linux-64                                   676.0kB @   2.2MB/s  0.3s\n",
            "libgcc-ng                                           29.2kB @  93.4kB/s  0.1s\n",
            "libstdcxx-ng                                        29.3kB @  80.8kB/s  0.1s\n",
            "zstd                                               567.6kB @   1.6MB/s  0.1s\n",
            "[+] 0.4s\n",
            "Downloading  (7)   4%\n",
            "Extracting   (6)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gzeromq                                             335.4kB @ 829.3kB/s  0.1s\n",
            "setuptools                                         748.8kB @   1.9MB/s  0.1s\n",
            "libssh2                                            304.8kB @ 744.4kB/s  0.2s\n",
            "wcwidth                                             32.6kB @  72.5kB/s  0.1s\n",
            "charset-normalizer                                  50.5kB @ 108.5kB/s  0.1s\n",
            "webencodings                                        15.5kB @  32.5kB/s  0.1s\n",
            "json5                                               34.1kB @  71.5kB/s  0.1s\n",
            "[+] 0.5s\n",
            "Downloading  (5)   5%\n",
            "Extracting  (10)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtyping_utils                                        15.2kB @  30.2kB/s  0.1s\n",
            "ptyprocess                                          19.5kB @  36.9kB/s  0.1s\n",
            "soupsieve                                           37.8kB @  71.3kB/s  0.1s\n",
            "typing_extensions                                   51.1kB @  96.4kB/s  0.1s\n",
            "sniffio                                             15.0kB @  27.5kB/s  0.1s\n",
            "comm                                                14.7kB @  25.5kB/s  0.1s\n",
            "webcolors                                           18.4kB @  31.8kB/s  0.1s\n",
            "python-json-logger                                  13.4kB @  23.1kB/s  0.1s\n",
            "[+] 0.6s\n",
            "Downloading  (5)   6%\n",
            "Extracting  (15)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtraitlets                                          110.1kB @ 180.5kB/s  0.1s\n",
            "overrides                                           30.1kB @  47.3kB/s  0.1s\n",
            "tinycss2                                            28.3kB @  44.2kB/s  0.1s\n",
            "rfc3987-syntax                                      22.9kB @  34.5kB/s  0.1s\n",
            "prompt-toolkit                                     271.8kB @ 403.4kB/s  0.1s\n",
            "websocket-client                                    46.7kB @  67.6kB/s  0.2s\n",
            "h11                                                 37.7kB @  54.5kB/s  0.1s\n",
            "[+] 0.7s\n",
            "Downloading  (5)   6%\n",
            "Extracting  (18)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gmistune                                             72.7kB @ 100.8kB/s  0.1s\n",
            "importlib-metadata                                  34.6kB @  47.6kB/s  0.1s\n",
            "bleach-with-css                                      4.2kB @   5.7kB/s  0.1s\n",
            "isoduration                                         19.8kB @  26.5kB/s  0.1s\n",
            "markupsafe                                          22.9kB @  29.5kB/s  0.0s\n",
            "anyio                                              126.3kB @ 161.1kB/s  0.1s\n",
            "pyyaml                                             181.8kB @ 230.1kB/s  0.1s\n",
            "[+] 0.8s\n",
            "Downloading  (5)   7%\n",
            "Extracting  (23)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcffi                                               241.6kB @ 296.2kB/s  0.1s\n",
            "jinja2                                             112.7kB @ 135.2kB/s  0.1s\n",
            "brotli-python                                      350.1kB @ 412.9kB/s  0.1s\n",
            "jsonschema-specifications                           19.2kB @  22.5kB/s  0.1s\n",
            "requests                                            59.4kB @  68.5kB/s  0.1s\n",
            "terminado                                           22.5kB @  25.8kB/s  0.1s\n",
            "[+] 0.9s\n",
            "Downloading  (5)   8%\n",
            "Extracting  (25)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnbformat                                           100.9kB @ 111.7kB/s  0.1s\n",
            "nbconvert-core                                     200.6kB @ 215.5kB/s  0.1s\n",
            "rhash                                              193.8kB @ 206.9kB/s  0.1s\n",
            "jupyter-lsp                                         58.4kB @  61.3kB/s  0.1s\n",
            "yaml                                                85.2kB @  87.0kB/s  0.1s\n",
            "[+] 1.0s\n",
            "Downloading  (5)   8%\n",
            "Extracting  (26)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibsodium                                          206.0kB @ 205.1kB/s  0.1s\n",
            "ncurses                                            891.6kB @ 886.6kB/s  0.1s\n",
            "readline                                           282.5kB @ 279.0kB/s  0.1s\n",
            "swig                                                 1.2MB @   1.2MB/s  0.1s\n",
            "pip                                                  1.2MB @   1.1MB/s  0.1s\n",
            "pandocfilters                                       11.6kB @  10.9kB/s  0.1s\n",
            "executing                                           29.7kB @  27.7kB/s  0.1s\n",
            "types-python-dateutil                               24.7kB @  22.5kB/s  0.1s\n",
            "[+] 1.1s\n",
            "Downloading  (5)  12%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpickleshare                                         11.7kB @  10.5kB/s  0.1s\n",
            "certifi                                            159.8kB @ 141.3kB/s  0.1s\n",
            "six                                                 18.5kB @  16.3kB/s  0.1s\n",
            "attrs                                               57.2kB @  50.2kB/s  0.1s\n",
            "send2trash                                          22.7kB @  19.7kB/s  0.1s\n",
            "pexpect                                             53.6kB @  45.2kB/s  0.0s\n",
            "stack_data                                          27.0kB @  22.8kB/s  0.1s\n",
            "[+] 1.2s\n",
            "Downloading  (5)  13%\n",
            "Extracting  (36)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtomli                                               21.2kB @  17.6kB/s  0.1s\n",
            "typing-extensions                                   90.5kB @  74.9kB/s  0.1s\n",
            "jupyter_core                                        59.6kB @  47.8kB/s  0.1s\n",
            "psutil                                             349.1kB @ 277.7kB/s  0.0s\n",
            "httpcore                                            49.5kB @  39.2kB/s  0.1s\n",
            "matplotlib-inline                                   14.5kB @  11.3kB/s  0.1s\n",
            "[+] 1.3s\n",
            "Downloading  (5)  17%\n",
            "Extracting  (42)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gargon2-cffi-bindings                                34.1kB @  26.2kB/s  0.0s\n",
            "pyzmq                                              335.2kB @ 252.9kB/s  0.1s\n",
            "urllib3                                            101.7kB @  76.7kB/s  0.1s\n",
            "jupyter_server_terminals                            19.7kB @  14.7kB/s  0.1s\n",
            "jupyter_events                                      23.6kB @  17.4kB/s  0.1s\n",
            "[+] 1.4s\n",
            "Downloading  (5)  19%\n",
            "Extracting  (46)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibexpat                                            74.8kB @  53.4kB/s  0.1s\n",
            "jupyterlab_server                                   49.4kB @  35.4kB/s  0.1s\n",
            "libuv                                              895.1kB @ 638.3kB/s  0.1s\n",
            "babel                                                6.9MB @   4.9MB/s  0.3s\n",
            "libsqlite                                          932.6kB @ 645.9kB/s  0.1s\n",
            "asttokens                                           28.2kB @  19.2kB/s  0.1s\n",
            "defusedxml                                          24.1kB @  16.2kB/s  0.1s\n",
            "libcurl                                            449.9kB @ 300.8kB/s  0.1s\n",
            "[+] 1.5s\n",
            "Downloading  (5)  24%\n",
            "Extracting  (52)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcached_property                                     11.1kB @   7.3kB/s  0.1s\n",
            "zipp                                                23.0kB @  14.9kB/s  0.1s\n",
            "packaging                                           62.5kB @  40.2kB/s  0.1s\n",
            "jupyterlab_pygments                                 18.7kB @  11.9kB/s  0.1s\n",
            "platformdirs                                        23.5kB @  14.8kB/s  0.1s\n",
            "[+] 1.6s\n",
            "Downloading  (5)  32%\n",
            "Extracting  (55)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcached-property                                      4.1kB @   2.6kB/s  0.0s\n",
            "beautifulsoup4                                     146.6kB @  90.4kB/s  0.1s\n",
            "exceptiongroup                                      21.3kB @  13.0kB/s  0.1s\n",
            "jupyter_client                                     106.3kB @  63.0kB/s  0.1s\n",
            "[+] 1.7s\n",
            "Downloading  (5)  44%\n",
            "Extracting  (55)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gdebugpy                                              2.2MB @   1.3MB/s  0.1s\n",
            "python                                              23.7MB @  13.8MB/s  0.3s\n",
            "jsonschema                                          81.5kB @  47.4kB/s  0.1s\n",
            "tornado                                            650.2kB @ 373.0kB/s  0.1s\n",
            "jupyter_server                                     344.4kB @ 195.4kB/s  0.1s\n",
            "libedit                                            134.7kB @  75.7kB/s  0.1s\n",
            "[+] 1.8s\n",
            "Downloading  (5)  53%\n",
            "Extracting  (61)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpytz                                               189.0kB @ 104.7kB/s  0.1s\n",
            "python-fastjsonschema                              226.3kB @ 124.0kB/s  0.1s\n",
            "openssl                                              3.1MB @   1.7MB/s  0.1s\n",
            "hpack                                               30.7kB @  16.7kB/s  0.1s\n",
            "rfc3986-validator                                    7.8kB @   4.2kB/s  0.1s\n",
            "bleach                                             141.4kB @  75.1kB/s  0.1s\n",
            "[+] 1.9s\n",
            "Downloading  (5)  60%\n",
            "Extracting  (66)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gasync-lru                                           17.3kB @   9.0kB/s  0.1s\n",
            "fqdn                                                16.7kB @   8.7kB/s  0.1s\n",
            "rpds-py                                            386.6kB @ 198.2kB/s  0.1s\n",
            "referencing                                         51.7kB @  26.1kB/s  0.1s\n",
            "nbclient                                            28.0kB @  14.2kB/s  0.1s\n",
            "[+] 2.0s\n",
            "Downloading  (5)  67%\n",
            "Extracting  (70)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gjsonschema-with-format-nongpl                        4.7kB @   2.3kB/s  0.1s\n",
            "decorator                                           14.1kB @   6.9kB/s  0.1s\n",
            "pure_eval                                           16.7kB @   8.0kB/s  0.1s\n",
            "[+] 2.1s\n",
            "Downloading  (5)  70%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Guri-template                                        24.0kB @  11.3kB/s  0.1s\n",
            "python-dateutil                                    233.3kB @ 110.1kB/s  0.1s\n",
            "arrow                                              100.0kB @  46.8kB/s  0.1s\n",
            "cmake                                               20.4MB @   9.3MB/s  0.5s\n",
            "jsonpointer                                         15.7kB @   7.2kB/s  0.1s\n",
            "zstandard                                          720.8kB @ 329.4kB/s  0.1s\n",
            "[+] 2.2s\n",
            "Downloading  (6)  81%\n",
            "Extracting  (75)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gliblzma                                            112.9kB @  51.2kB/s  0.1s\n",
            "parso                                               75.3kB @  33.4kB/s  0.1s\n",
            "ipython                                            591.0kB @ 261.7kB/s  0.1s\n",
            "jedi                                               843.6kB @ 371.1kB/s  0.1s\n",
            "[+] 2.3s\n",
            "Downloading  (5)  84%\n",
            "Extracting  (77)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpygments                                           889.3kB @ 385.1kB/s  0.1s\n",
            "ipykernel                                          120.3kB @  51.8kB/s  0.1s\n",
            "hyperframe                                          17.4kB @   7.5kB/s  0.1s\n",
            "tk                                                   3.3MB @   1.4MB/s  0.4s\n",
            "libstdcxx                                            3.9MB @   1.6MB/s  0.1s\n",
            "rfc3339-validator                                   10.2kB @   4.3kB/s  0.1s\n",
            "[+] 2.4s\n",
            "Downloading  (5)  90%\n",
            "Extracting  (81)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gargon2-cffi                                         18.7kB @   7.8kB/s  0.1s\n",
            "notebook-shim                                       16.8kB @   6.9kB/s  0.1s\n",
            "prometheus_client                                   52.6kB @  21.7kB/s  0.1s\n",
            "httpx                                               63.1kB @  25.5kB/s  0.0s\n",
            "[+] 2.5s\n",
            "Downloading  (5)  91%\n",
            "Extracting  (84)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnest-asyncio                                        11.5kB @   4.6kB/s  0.1s\n",
            "lark                                                92.1kB @  36.6kB/s  0.1s\n",
            "pcre2                                                1.2MB @ 476.1kB/s  0.2s\n",
            "h2                                                  53.9kB @  21.3kB/s  0.1s\n",
            "[+] 2.6s\n",
            "Downloading  (1)  95%\n",
            "Extracting  (87)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gjupyterlab                                           8.1MB @   3.0MB/s  0.3s\n",
            "[+] 2.7s\n",
            "Downloading      100%\n",
            "Extracting  (86)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
            "Downloading      100%\n",
            "Extracting  (85)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
            "Downloading      100%\n",
            "Extracting  (81)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
            "Downloading      100%\n",
            "Extracting  (80)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
            "Downloading      100%\n",
            "Extracting  (79)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
            "Downloading      100%\n",
            "Extracting  (79)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
            "Downloading      100%\n",
            "Extracting  (78)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
            "Downloading      100%\n",
            "Extracting  (77)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
            "Downloading      100%\n",
            "Extracting  (76)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
            "Downloading      100%\n",
            "Extracting  (74)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
            "Downloading      100%\n",
            "Extracting  (68)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
            "Downloading      100%\n",
            "Extracting  (64)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
            "Downloading      100%\n",
            "Extracting  (61)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
            "Downloading      100%\n",
            "Extracting  (57)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
            "Downloading      100%\n",
            "Extracting  (53)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
            "Downloading      100%\n",
            "Extracting  (49)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
            "Downloading      100%\n",
            "Extracting  (46)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
            "Downloading      100%\n",
            "Extracting  (44)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
            "Downloading      100%\n",
            "Extracting  (40)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
            "Downloading      100%\n",
            "Extracting  (36)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
            "Downloading      100%\n",
            "Extracting  (35)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
            "Downloading      100%\n",
            "Extracting  (32)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
            "Downloading      100%\n",
            "Extracting  (29)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
            "Downloading      100%\n",
            "Extracting  (29)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
            "Downloading      100%\n",
            "Extracting  (28)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
            "Downloading      100%\n",
            "Extracting  (27)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
            "Downloading      100%\n",
            "Extracting  (26)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
            "Downloading      100%\n",
            "Extracting  (25)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
            "Downloading      100%\n",
            "Extracting  (24)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
            "Downloading      100%\n",
            "Extracting  (23)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
            "Downloading      100%\n",
            "Extracting  (22)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
            "Downloading      100%\n",
            "Extracting  (21)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
            "Downloading      100%\n",
            "Extracting  (19)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
            "Downloading      100%\n",
            "Extracting  (17)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
            "Downloading      100%\n",
            "Extracting  (15)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
            "Downloading      100%\n",
            "Extracting  (14)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
            "Downloading      100%\n",
            "Extracting  (14)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.3s\n",
            "Downloading      100%\n",
            "Extracting  (11)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
            "Downloading      100%\n",
            "Extracting   (9)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.5s\n",
            "Downloading      100%\n",
            "Extracting   (8)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
            "Downloading      100%\n",
            "Extracting   (7)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
            "Downloading      100%\n",
            "Extracting   (6)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.8s\n",
            "Downloading      100%\n",
            "Extracting   (4)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.9s\n",
            "Downloading      100%\n",
            "Extracting   (3)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.0s\n",
            "Downloading      100%\n",
            "Extracting       100%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "To activate this environment, use\n",
            "\n",
            "     $ mamba activate autosklearn-env\n",
            "\n",
            "To deactivate an active environment, use\n",
            "\n",
            "     $ mamba deactivate\n",
            "\n",
            "Collecting auto-sklearn\n",
            "  Downloading auto-sklearn-0.15.0.tar.gz (6.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 68.4 MB/s  0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from auto-sklearn) (80.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from auto-sklearn) (4.14.1)\n",
            "Collecting distro (from auto-sklearn)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting numpy>=1.9.0 (from auto-sklearn)\n",
            "  Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting scipy>=1.7.0 (from auto-sklearn)\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting joblib (from auto-sklearn)\n",
            "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting scikit-learn<0.25.0,>=0.24.0 (from auto-sklearn)\n",
            "  Downloading scikit_learn-0.24.2-cp39-cp39-manylinux2010_x86_64.whl.metadata (9.8 kB)\n",
            "Collecting dask>=2021.12 (from auto-sklearn)\n",
            "  Downloading dask-2024.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting distributed>=2012.12 (from auto-sklearn)\n",
            "  Downloading distributed-2024.8.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from auto-sklearn) (6.0.2)\n",
            "Collecting pandas>=1.0 (from auto-sklearn)\n",
            "  Downloading pandas-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Collecting liac-arff (from auto-sklearn)\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting threadpoolctl (from auto-sklearn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting ConfigSpace<0.5,>=0.4.21 (from auto-sklearn)\n",
            "  Downloading ConfigSpace-0.4.21-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting pynisher<0.7,>=0.6.3 (from auto-sklearn)\n",
            "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pyrfr<0.9,>=0.8.1 (from auto-sklearn)\n",
            "  Downloading pyrfr-0.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (601 bytes)\n",
            "Collecting smac<1.3,>=1.2 (from auto-sklearn)\n",
            "  Downloading smac-1.2.tar.gz (260 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting cython (from ConfigSpace<0.5,>=0.4.21->auto-sklearn)\n",
            "  Downloading cython-3.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting pyparsing (from ConfigSpace<0.5,>=0.4.21->auto-sklearn)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from pynisher<0.7,>=0.6.3->auto-sklearn) (7.0.0)\n",
            "Collecting emcee>=3.0.0 (from smac<1.3,>=1.2->auto-sklearn)\n",
            "  Downloading emcee-3.1.6-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting click>=8.1 (from dask>=2021.12->auto-sklearn)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cloudpickle>=1.5.0 (from dask>=2021.12->auto-sklearn)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting fsspec>=2021.09.0 (from dask>=2021.12->auto-sklearn)\n",
            "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from dask>=2021.12->auto-sklearn) (25.0)\n",
            "Collecting partd>=1.4.0 (from dask>=2021.12->auto-sklearn)\n",
            "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting toolz>=0.10.0 (from dask>=2021.12->auto-sklearn)\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from dask>=2021.12->auto-sklearn) (8.7.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from distributed>=2012.12->auto-sklearn) (3.1.6)\n",
            "Collecting locket>=1.0.0 (from distributed>=2012.12->auto-sklearn)\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting msgpack>=1.0.0 (from distributed>=2012.12->auto-sklearn)\n",
            "  Downloading msgpack-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed>=2012.12->auto-sklearn)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed>=2012.12->auto-sklearn)\n",
            "  Downloading tblib-3.1.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from distributed>=2012.12->auto-sklearn) (6.5.1)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from distributed>=2012.12->auto-sklearn) (2.5.0)\n",
            "Collecting zict>=3.0.0 (from distributed>=2012.12->auto-sklearn)\n",
            "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from importlib-metadata>=4.13.0->dask>=2021.12->auto-sklearn) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from jinja2>=2.10.3->distributed>=2012.12->auto-sklearn) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from pandas>=1.0->auto-sklearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from pandas>=1.0->auto-sklearn) (2025.2)\n",
            "Collecting tzdata>=2022.7 (from pandas>=1.0->auto-sklearn)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/autosklearn-env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.0->auto-sklearn) (1.17.0)\n",
            "Downloading ConfigSpace-0.4.21-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 97.0 MB/s  0:00:00\n",
            "Downloading pyrfr-0.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 95.3 MB/s  0:00:00\n",
            "Downloading scikit_learn-0.24.2-cp39-cp39-manylinux2010_x86_64.whl (23.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.8/23.8 MB 118.0 MB/s  0:00:00\n",
            "Downloading dask-2024.8.0-py3-none-any.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 50.4 MB/s  0:00:00\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading distributed-2024.8.0-py3-none-any.whl (1.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 42.4 MB/s  0:00:00\n",
            "Downloading emcee-3.1.6-py2.py3-none-any.whl (47 kB)\n",
            "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
            "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading msgpack-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
            "Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.5/19.5 MB 120.1 MB/s  0:00:00\n",
            "Downloading pandas-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 102.5 MB/s  0:00:00\n",
            "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.6/38.6 MB 37.5 MB/s  0:00:01\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tblib-3.1.0-py3-none-any.whl (12 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "Downloading cython-3.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 81.3 MB/s  0:00:00\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Building wheels for collected packages: auto-sklearn, pynisher, smac, liac-arff\n",
            "  Building wheel for auto-sklearn (pyproject.toml): started\n",
            "  Building wheel for auto-sklearn (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.15.0-py3-none-any.whl size=6642041 sha256=cb152cae55ddef11262926d5636a701d287a0d1c3726cadf04233529a2e9dea2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/47/fd/4ef4e0ab13b80ba38029f84a188f67e6205a63e3416f5b8bf7\n",
            "  Building wheel for pynisher (setup.py): started\n",
            "  Building wheel for pynisher (setup.py): finished with status 'done'\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7094 sha256=6f26507e7b7e5667600ec33a0f4028c8521da4335a64bf41902be43e84814fb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/de/5e/d4947b76b76ba27581d1e09f395eca1583a802203a41c04873\n",
            "  Building wheel for smac (setup.py): started\n",
            "  Building wheel for smac (setup.py): finished with status 'done'\n",
            "  Created wheel for smac: filename=smac-1.2-py3-none-any.whl size=215971 sha256=1881a5e1202a8811900ca0d039671cada55061bf3fa09db9d29876b2dd6236b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/3d/a9/7039d2989e5f6b803942a48ec440ab72530234d8809c01cb0e\n",
            "  Building wheel for liac-arff (setup.py): started\n",
            "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11768 sha256=e66a9f357b4c5167253ec5d5fed43f88ed4e45f9e557ff46e218efc1b8728cfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/82/8b/5c514221984e88c059b94e36a71d4722e590acaae04deab22e\n",
            "Successfully built auto-sklearn pynisher smac liac-arff\n",
            "Installing collected packages: sortedcontainers, zict, tzdata, toolz, threadpoolctl, tblib, pyrfr, pyparsing, pynisher, numpy, msgpack, locket, liac-arff, joblib, fsspec, distro, cython, cloudpickle, click, scipy, partd, pandas, emcee, scikit-learn, dask, ConfigSpace, distributed, smac, auto-sklearn\n",
            "\n",
            "Successfully installed ConfigSpace-0.4.21 auto-sklearn-0.15.0 click-8.1.8 cloudpickle-3.1.1 cython-3.1.2 dask-2024.8.0 distributed-2024.8.0 distro-1.9.0 emcee-3.1.6 fsspec-2025.7.0 joblib-1.5.1 liac-arff-2.5.0 locket-1.0.0 msgpack-1.1.1 numpy-2.0.2 pandas-2.3.1 partd-1.4.2 pynisher-0.6.4 pyparsing-3.2.3 pyrfr-0.8.3 scikit-learn-0.24.2 scipy-1.13.1 smac-1.2 sortedcontainers-2.4.0 tblib-3.1.0 threadpoolctl-3.6.0 toolz-1.0.0 tzdata-2025.2 zict-3.0.0\n",
            "\n",
            "  DEPRECATION: Building 'pynisher' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pynisher'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
            "  DEPRECATION: Building 'smac' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'smac'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
            "  DEPRECATION: Building 'liac-arff' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'liac-arff'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mamba create -n autosklearn-env -c conda-forge python=3.9 jupyterlab swig cmake -y\n",
        "!mamba run -n autosklearn-env pip install auto-sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mamba run -n autosklearn-env python -c \"import autosklearn.classification; print('Auto-Sklearn Installed!')\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwf7RBnzWl4s",
        "outputId": "5f1c1b94-3066-4030-d7d1-951cf679e2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/envs/autosklearn-env/lib/python3.9/site-packages/autosklearn/__init__.py:5: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/local/envs/autosklearn-env/lib/python3.9/site-packages/autosklearn/classification.py\", line 1, in <module>\n",
            "    from autosklearn.estimators import AutoSklearnClassifier  # noqa (imported but unused)\n",
            "  File \"/usr/local/envs/autosklearn-env/lib/python3.9/site-packages/autosklearn/estimators.py\", line 23, in <module>\n",
            "    from ConfigSpace.configuration_space import Configuration, ConfigurationSpace\n",
            "  File \"/usr/local/envs/autosklearn-env/lib/python3.9/site-packages/ConfigSpace/__init__.py\", line 37, in <module>\n",
            "    from ConfigSpace.configuration_space import Configuration, \\\n",
            "  File \"ConfigSpace/configuration_space.pyx\", line 40, in init ConfigSpace.configuration_space\n",
            "  File \"ConfigSpace/hyperparameters.pyx\", line 1, in init ConfigSpace.hyperparameters\n",
            "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
            "\n",
            "ERROR conda.cli.main_run:execute(125): `conda run python -c import autosklearn.classification; print('Auto-Sklearn Installed!')` failed. (See above for error)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdKPgB4HuQys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "a1cc4c7f-872e-4b33-9dd9-252973714ca5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'autosklearn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2539726052.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoSklearnClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import kagglehub\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from autosklearn.classification import AutoSklearnClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import tabulate\n",
        "import seaborn as sns\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0CFdGBDvB2x"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"pavansubhasht/ibm-hr-analytics-attrition-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch8uI5xlvJE2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path + \"/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tThL6EfFvmWV"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qy1S5YRv1zj"
      },
      "outputs": [],
      "source": [
        "# Check for missing / invalid values\n",
        "print(df.isna().sum().sum())\n",
        "print(df.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We8Kyf39SZvw"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCnssr9GMzbT"
      },
      "outputs": [],
      "source": [
        "## Lets analyze some relations to gain insight between some protected class parameters and attrition\n",
        "\n",
        "def plot_attrition(column):\n",
        "\n",
        "  attrition_counts = pd.crosstab(df[column], df['Attrition'])\n",
        "  attrition_percentages = attrition_counts.div(attrition_counts.sum(axis=1), axis=0)\n",
        "  ax = attrition_percentages.plot(kind='bar', stacked=True, figsize=(10, 5))\n",
        "  for container in ax.containers:\n",
        "      labels = [f'{w:.1%}' if (w := v.get_height()) > 0 else '' for v in container]\n",
        "      ax.bar_label(container, labels=labels, label_type='center')\n",
        "\n",
        "\n",
        "  plt.title(column + ' vs Attrition')\n",
        "  plt.xlabel(column)\n",
        "  plt.xticks(rotation = 45)\n",
        "  plt.ylabel('Attrition')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_attrition('BusinessTravel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgZyOC4dSR3S"
      },
      "outputs": [],
      "source": [
        "plot_attrition('Department')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSlukbyeSoK1"
      },
      "outputs": [],
      "source": [
        "plot_attrition('EducationField')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZpjEOXESqYT"
      },
      "outputs": [],
      "source": [
        "plot_attrition('JobRole')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPqBvaK3Stp2"
      },
      "outputs": [],
      "source": [
        "plot_attrition('MaritalStatus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M7vD_qNS7MH"
      },
      "outputs": [],
      "source": [
        "plot_attrition('Gender')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2yQlLxZw4Q9"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encode Categorical Variables\n",
        "\n",
        "df = df.join(pd.get_dummies(df['BusinessTravel'], prefix = 'BusinessTravel')).drop('BusinessTravel', axis = 1)\n",
        "df = df.join(pd.get_dummies(df['Department'], prefix = 'Department')).drop('Department', axis = 1)\n",
        "df = df.join(pd.get_dummies(df['EducationField'], prefix = 'Education')).drop('EducationField', axis = 1)\n",
        "df = df.join(pd.get_dummies(df['JobRole'], prefix = 'Job')).drop('JobRole', axis = 1)\n",
        "df = df.join(pd.get_dummies(df['MaritalStatus'])).drop('MaritalStatus', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEw6NTvtzQEV"
      },
      "outputs": [],
      "source": [
        "# Binary Encode\n",
        "\n",
        "df['Attrition'].replace({'Yes': 1, 'No': 0}, inplace = True)\n",
        "df['Gender'].replace({'Male': 1, 'Female': 0}, inplace = True)\n",
        "df['Over18'].replace({'Y': 1, 'N': 0}, inplace = True)\n",
        "df['OverTime'].replace({'Yes': 1, 'No': 0}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NqqEmXIwwFU"
      },
      "outputs": [],
      "source": [
        "# Binary Encode the One-Hot Encoded Parameters\n",
        "\n",
        "df.replace({True: 1, False: 0}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJDkO4nw2IOU"
      },
      "outputs": [],
      "source": [
        "df.hist(figsize = (20, 20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djFwb7lJ2h9z"
      },
      "outputs": [],
      "source": [
        "# Drop unncessary columns\n",
        "\n",
        "df = df.drop(['EmployeeCount', 'Over18', 'StandardHours'], axis = 1) # Entire column has the same value\n",
        "df = df.drop(['EmployeeNumber'], axis = 1) # Can be used as an identifier but we are using dataset indexing\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMuH6mYI17oO"
      },
      "outputs": [],
      "source": [
        "# Standardize the dataset\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jUNOEnXdies"
      },
      "outputs": [],
      "source": [
        "corr_matrix=df.corr()\n",
        "stacked_corr = corr_matrix.stack()\n",
        "filtered_corr = stacked_corr[abs(stacked_corr) > 0.95]\n",
        "filtered_corr = filtered_corr[filtered_corr.index.get_level_values(0) != filtered_corr.index.get_level_values(1)]\n",
        "\n",
        "print(\"Combinations with correlation greater than 0.94 (absolute value):\")\n",
        "filtered_corr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEsoBJesdvBu"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots(figsize=(15,10))\n",
        "ax=sns.heatmap(corr_matrix,\n",
        "               linewidths=0.2,\n",
        "               fmt=\".1f\"\n",
        "              )\n",
        "df = df.drop(['JobLevel'], axis = 1) # Remove extremely correlated columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta6Fo-QU3lpJ"
      },
      "source": [
        "## Training / Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lPyYlaUTvgt"
      },
      "outputs": [],
      "source": [
        "def training_testing(df, model, batch_size ,title, scores_title, verbose = False):\n",
        "  # Split the dataset\n",
        "\n",
        "  X, y = df.drop('Attrition', axis = 1), df['Attrition']\n",
        "\n",
        "  model = model\n",
        "  start = time.time()\n",
        "  test = []\n",
        "  train = []\n",
        "\n",
        "  res = 0\n",
        "  optimal_model = None\n",
        "  for i in range(batch_size):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    test.append(model.score(X_test, y_test))\n",
        "    train.append(model.score(X_train, y_train))\n",
        "\n",
        "\n",
        "  end = time.time()\n",
        "  mean_accuracy = sum(test) / batch_size\n",
        "  if mean_accuracy > res and mean_accuracy > 0.88:\n",
        "    res = mean_accuracy\n",
        "    optimal_model = model\n",
        "    print(optimal_model, f\"Accuracy: {res}\")\n",
        "\n",
        "\n",
        "  if verbose == True:\n",
        "    print(\"############################ \" + title + \" ############################ \\n\")\n",
        "    print('Total Training Time: ' + str(end - start))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print('Mean Train Accuracy: ' , sum(train) / batch_size)\n",
        "    print('Mean Test Accuracy: ' , mean_accuracy)\n",
        "    print(\"########################################################################################################################## \\n\")\n",
        "  # sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap = 'Blues', fmt = 'g')\n",
        "  # plt.title(title)\n",
        "  # plt.show()\n",
        "  return model, {scores_title: mean_accuracy}, optimal_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRz2slEr5WVt"
      },
      "outputs": [],
      "source": [
        "# Random Forest Classifier\n",
        "rt_clf = RandomForestClassifier(n_estimators = 150, n_jobs = -1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Logistic Regression Classifier\n",
        "log_reg = LogisticRegression('l2', tol = 0.01,  C = 10, solver = 'liblinear')\n",
        "      # tol = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1] # Ideal tol = 0.01\n",
        "      # C = [0.01, 0.1, 1, 10, 100] # Ideal C = 10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# K Nearest Neighbors\n",
        "knn_clf = KNeighborsClassifier(16, weights = 'distance', n_jobs = -1, p = 1)\n",
        "      # k = list(range(1, 20)) # Ideal - K = 16\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Support Vector Machine\n",
        "svm_clf = svm.SVC(C = 50, degree = 1, tol = 1, kernel = 'poly')\n",
        "      # c = [0.001, 0.01, 0.1, 1, 10, 100] # Ideal C = 50\n",
        "      # degree = list(range(1,10)) # Ideal degree = 1\n",
        "      # tol = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1] # Ideal tol = 1\n",
        "\n",
        "\n",
        "\n",
        "# Gaussian Bernoulli Distribution Classifier\n",
        "nb_clf = GaussianNB(var_smoothing  = 1)\n",
        "      # var_s = [(10 * 10**(-x)) for x in range(11)] # Ideal var_smoothing = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUwHVy3MiQ-f"
      },
      "outputs": [],
      "source": [
        "# Custom Validation and optimal parameters\n",
        "\n",
        "\n",
        "batch_size = 20\n",
        "scores = pd.DataFrame()\n",
        "\n",
        "\n",
        "rtc_model, rtc_accuracy, optimal_model = training_testing(df, rt_clf , batch_size, \"All Features - Random Forest Classifier\", \"Random_Forest\", )\n",
        "dtc_model, dtc_accuracy, optimal_model = training_testing(df, dt_clf, batch_size, \"All Features - Decision Tree Classifier\", \"Decision_Tree\", )\n",
        "lr_model, lr_accuracy, optimal_model = training_testing(df, log_reg, batch_size, \"All Features - Logistic Regression - Tol: 0.01 - C: 10\" , \"Logisitic_Regression\", )\n",
        "knn_model, knn_accuracy, optimal_model = training_testing(df, knn_clf, batch_size, \"All Features - KNN - K = 16\", \"KNN\",)\n",
        "svm_model, svm_accuracy, optimal_model = training_testing(df, svm_clf, batch_size, f\"All Features - SVM - C: {50} - Degree: {1} - Tol: {1}\", \"SVM\", )\n",
        "nb_model, nb_accuracy, optimal_model = training_testing(df, nb_clf, batch_size, f\"All Features - Naive Bayes - var_smooting = 1\", \"Naive_Bayes\", )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FNrAcVeCTsn"
      },
      "outputs": [],
      "source": [
        "## AUTOML\n",
        "resample_s = {'train_size': 0.8,\n",
        "              'shuffle': True,\n",
        "              'folds': 5}\n",
        "automl_clf = AutoSklearnClassifier(time_left_for_this_task = 180, per_run_time_limit = 30, ensemble_size = 5,\n",
        "                                   resampling_strategy = 'cv-iterative-fit', resampling_strategy_arguments = resample_s,\n",
        "                                   n_jobs = -1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_LznBzF5nfa"
      },
      "outputs": [],
      "source": [
        "important_features = pd.Series(rt_clf.feature_importances_, index=X.columns)\n",
        "important_features.nlargest(30).plot(kind='barh')\n",
        "important_features.nlargest(30).index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OdSqqpRFmVI"
      },
      "outputs": [],
      "source": [
        "## Train only using the most impactful features\n",
        "\n",
        "mi_df = df[important_features.nlargest(30).index].join(df['Attrition'])\n",
        "mi_df\n",
        "\n",
        "\n",
        "## Split the dataset\n",
        "\n",
        "mi_X, mi_y = mi_df.drop('Attrition', axis = 1), mi_df['Attrition']\n",
        "mi_X_train, mi_X_test, mi_y_train, mi_y_test = train_test_split(mi_X, mi_y, test_size = 0.2)\n",
        "\n",
        "\n",
        "## Retrain and check accuracy\n",
        "\n",
        "mi_rt_clf = training_testing(mi_X_train, mi_y_train, mi_X_test, mi_y_test, RandomForestClassifier(n_estimators = 150, n_jobs = -1), batch_size, \"Preprocessed Dataset - Most Important Features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_NYeGu5Gs2n"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4KJbjYLhwqM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}